{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Mis Apuntes de Big Data","text":"<p>Bienvenido a mi wiki personal. Aqu\u00ed ir\u00e9 subiendo todo lo que aprenda sobre Hadoop, Spark y el ecosistema Big Data.</p>"},{"location":"#estructura-del-curso","title":"Estructura del curso","text":"<p>Haz clic en los enlaces para ir a cada tema:</p> <ul> <li>M\u00f3dulo 1: Teor\u00eda y Fundamentos</li> <li>M\u00f3dulo 2: Ecosistema Hadoop</li> <li>M\u00f3dulo 3: Instalaci\u00f3n y Pr\u00e1ctica</li> <li>M\u00f3dulo 4: YARN y MapReduce</li> <li>M\u00f3dulo 5: YARN Scheduler</li> </ul>"},{"location":"#chuleta-como-actualizar-estos-apuntes","title":"\ud83d\udcdd Chuleta: C\u00f3mo actualizar estos apuntes","text":"<p>Cada vez que se a\u00f1ada contenido nuevo, hay que seguir estos pasos en la terminal para que se vean reflejados en GitHub Pages:</p> <p>Pasos para publicar cambios</p> <ol> <li>Guardar cambios en local: <pre><code>git add .\ngit commit -m \"A\u00f1adida unidad 5 de YARN Scheduler\"\n</code></pre></li> <li>Subir al repositorio de c\u00f3digo: <pre><code>git push origin main\n</code></pre></li> <li>Desplegar en la web (GitHub Pages): <pre><code>mkdocs gh-deploy\n</code></pre></li> </ol> <p>Nota sobre el Scheduler</p> <p>Tener en cuenta que los cambios en el men\u00fa se configuran siempre en el archivo ra\u00edz <code>mkdocs.yml</code>. [cite: 13, 190]</p>"},{"location":"modulo1/chuleta/","title":"\ud83d\uddfa\ufe0f Mapa Mental: Linux vs. HDFS","text":"<p>Es vital diferenciar d\u00f3nde estamos trabajando. Tenemos dos sistemas de archivos paralelos que no se tocan directamente.</p>"},{"location":"modulo1/chuleta/#1-los-dos-universos","title":"1. Los Dos Universos","text":"Universo Linux Local (Tu PC) Hadoop (HDFS) \u00bfQu\u00e9 es? El disco duro f\u00edsico de tu m\u00e1quina virtual. Un sistema virtual repartido entre muchos nodos. \u00bfC\u00f3mo empiezo? Comandos normales (<code>ls</code>, <code>cd</code>). Siempre empieza por <code>hdfs dfs ...</code> \u00bfPuedo entrar (<code>cd</code>)? \u2705 S\u00ed. Te mueves por las carpetas. \u274c NO. No puedes \"entrar\". Solo puedes listar desde fuera."},{"location":"modulo1/chuleta/#2-diccionario-de-traduccion","title":"2. Diccionario de Traducci\u00f3n","text":"<p>Si quieres hacer algo en Hadoop, busca su equivalente:</p> Acci\u00f3n En Linux (Local) En Hadoop (HDFS) Listar archivos <code>ls -l</code> <code>hdfs dfs -ls /ruta</code> Crear carpeta <code>mkdir carpeta</code> <code>hdfs dfs -mkdir /ruta/carpeta</code> Borrar archivo <code>rm archivo</code> <code>hdfs dfs -rm /ruta/archivo</code> Ver contenido <code>cat archivo</code> <code>hdfs dfs -cat /ruta/archivo</code> Cambiar permisos <code>chmod 777</code> <code>hdfs dfs -chmod 777 /ruta</code>"},{"location":"modulo1/chuleta/#3-el-puente-subir-y-bajar-datos","title":"3. El \"Puente\" (Subir y Bajar datos)","text":"<p>Como son dos mundos separados, necesitamos comandos para mover archivos de uno a otro.</p> <ul> <li> <p>Subir (De Linux \u27a1 HDFS):</p> <ul> <li><code>put</code>: <code>hdfs dfs -put mi_foto.jpg /fotos</code></li> <li>(Significa: \"Coge mi_foto.jpg de aqu\u00ed y ponla en la carpeta /fotos de Hadoop\")</li> </ul> </li> <li> <p>Bajar (De HDFS \u27a1 Linux):</p> <ul> <li><code>get</code>: <code>hdfs dfs -get /fotos/mi_foto.jpg .</code></li> <li>(Significa: \"Trae la foto de Hadoop y d\u00e9jala aqu\u00ed mismo en mi Linux\")</li> </ul> </li> </ul>"},{"location":"modulo1/intro/","title":"Introducci\u00f3n al Big Data","text":""},{"location":"modulo1/intro/#1-que-es-big-data","title":"1. \u00bfQu\u00e9 es Big Data?","text":"<p>No es solo \"muchos datos\". Es el tratamiento y an\u00e1lisis de enormes repositorios de datos que son tan desproporcionadamente grandes que resulta imposible tratarlos con las herramientas de bases de datos y anal\u00edticas convencionales.</p> <p>Regla de Oro</p> <p>Si tus datos caben en una hoja de Excel o en una base de datos SQL tradicional y el tiempo de respuesta es aceptable, NO necesitas Big Data.</p>"},{"location":"modulo1/intro/#2-las-5-v-del-big-data","title":"2. Las 5 V del Big Data","text":"<p>Para que un problema se considere Big Data, suele cumplir estas caracter\u00edsticas:</p> <ul> <li>Volumen: La cantidad de datos (Terabytes, Petabytes...).</li> <li>Velocidad: La rapidez con la que se generan y procesan los datos (ej. sensores, streaming).</li> <li>Variedad: Distintos formatos. No solo texto, tambi\u00e9n video, audio, logs, redes sociales.</li> <li>Veracidad: La calidad y fiabilidad del dato (limpiar el \"ruido\").</li> <li>Valor: La capacidad de convertir esos datos en dinero o decisiones \u00fatiles.</li> </ul>"},{"location":"modulo1/intro/#3-tipos-de-datos","title":"3. Tipos de Datos","text":"Tipo Descripci\u00f3n Ejemplo Estructurados Tienen formato fijo y definido. Tablas SQL, Excel, CSV. No Estructurados No tienen estructura interna clara. V\u00eddeo, Audio, PDF, Emails. Semi-estructurados Tienen etiquetas pero no esquema r\u00edgido. HTML, XML, JSON."},{"location":"modulo1/practica/","title":"Pr\u00e1ctica Unidad 1: Instalaci\u00f3n de Hadoop","text":"<p>Esta p\u00e1gina documenta la entrega de la pr\u00e1ctica de la Unidad 1, detallando el proceso de instalaci\u00f3n base de Hadoop en modo Pseudo-distribuido.</p>"},{"location":"modulo1/practica/#objetivos-de-la-practica","title":"\ud83c\udfaf Objetivos de la Pr\u00e1ctica","text":"<p>Realizar una instalaci\u00f3n funcional que cumpla con los siguientes requisitos: 1.  C\u00f3digo fuente: Ubicado en <code>/opt/hadoop</code>. 2.  Java: Instalaci\u00f3n de JDK8 (Open o Privado). 3.  SSH: Instalaci\u00f3n y configuraci\u00f3n para acceso sin contrase\u00f1a. 4.  Variables de Entorno: Configuraci\u00f3n para ejecutar comandos desde cualquier ruta.</p>"},{"location":"modulo1/practica/#desarrollo-de-la-instalacion","title":"\ud83d\udee0\ufe0f Desarrollo de la Instalaci\u00f3n","text":""},{"location":"modulo1/practica/#1-despliegue-del-codigo-fuente","title":"1. Despliegue del C\u00f3digo Fuente","text":"<p>Se ha descargado y descomprimido Hadoop en el directorio est\u00e1ndar de Linux para software opcional.</p> <ul> <li>Ruta de instalaci\u00f3n: <code>/opt/hadoop</code></li> <li>Permisos: El usuario actual es propietario de la carpeta.</li> </ul> <pre><code># Verificaci\u00f3n\nls -ld /opt/hadoop\n</code></pre>"},{"location":"modulo1/practica/#2-instalacion-de-java-jdk-8","title":"2. Instalaci\u00f3n de Java (JDK 8)","text":"<p>Hadoop requiere Java 8 para funcionar correctamente. Se ha instalado openjdk-8-jdk <pre><code># Verificaci\u00f3n de versi\u00f3n\njava -version\n# Salida esperada: openjdk version \"1.8.0_...\"\n</code></pre></p>"},{"location":"modulo1/practica/#3-configuracion-ssh","title":"3. Configuraci\u00f3n SSH","text":"<p>Para que los scripts de arranque (start-dfs.sh, start-yarn.sh) funcionen, el nodo debe poder conectarse a s\u00ed mismo sin pedir contrase\u00f1a.</p> <ul> <li> <p>Clave generada con: ssh-keygen -t rsa</p> <ul> <li>Clave copiada con: ssh-copy-id localhost</li> </ul> </li> </ul> <pre><code># Prueba de conexi\u00f3n (no debe pedir password)\nssh localhost\n</code></pre>"},{"location":"modulo1/practica/#4-variables-de-entorno-bashrc","title":"4. Variables de Entorno (.bashrc)","text":"<p>Se han a\u00f1adido las rutas al archivo .bashrc para que el sistema reconozca los comandos de Hadoop globalmente.</p> <p>Configuraci\u00f3n aplicada:</p> <pre><code>export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\nexport HADOOP_HOME=/opt/hadoop\nexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\n</code></pre> <p>Verificaci\u00f3n:</p> <pre><code># Ejecutado desde la carpeta HOME (~)\nhadoop version\n</code></pre>"},{"location":"modulo2/core/","title":"El Ecosistema Hadoop","text":""},{"location":"modulo2/core/#1-arquitectura-maestro-esclavo","title":"1. Arquitectura: Maestro - Esclavo","text":"<p>Hadoop funciona como un ej\u00e9rcito. Un nodo manda y los dem\u00e1s obedecen.</p> <ul> <li>Master (Maestro): Gestiona, coordina y sabe d\u00f3nde est\u00e1 todo.</li> <li>Slave (Esclavo): Hace el trabajo sucio (guardar datos o procesar c\u00e1lculos).</li> <li>Commodity Hardware: Hadoop est\u00e1 dise\u00f1ado para ejecutarse en ordenadores \"baratos\" y normales, no en superordenadores.</li> </ul>"},{"location":"modulo2/core/#2-los-dos-pilares-de-hadoop","title":"2. Los Dos Pilares de Hadoop","text":""},{"location":"modulo2/core/#a-hdfs-almacenamiento","title":"A. HDFS (Almacenamiento)","text":"<p>Es el sistema de archivos distribuido. Rompe los archivos en bloques y los reparte. * NameNode (Maestro): El \u00edndice. Sabe en qu\u00e9 nodo est\u00e1 cada trozo de archivo. * DataNode (Esclavo): El almac\u00e9n. Guarda los bloques de datos f\u00edsicamente. * Replicaci\u00f3n: Por defecto, cada bloque se guarda 3 veces en distintos nodos para evitar p\u00e9rdidas si un disco se rompe.</p>"},{"location":"modulo2/core/#b-yarn-procesamiento","title":"B. YARN (Procesamiento)","text":"<p>Es el sistema operativo del cl\u00faster. Reparte la RAM y la CPU. * ResourceManager (Maestro): Decide cu\u00e1ntos recursos le da a cada tarea. * NodeManager (Esclavo): Vigila el uso de CPU/RAM en cada m\u00e1quina.</p>"},{"location":"modulo2/core/#3-mapreduce-vs-spark","title":"3. MapReduce vs Spark","text":"<p>Son las formas de \"trabajar\" con los datos.</p> <p>MapReduce (El Cl\u00e1sico)</p> <ul> <li>Trabaja escribiendo mucho en disco duro.</li> <li>Es lento y por lotes (Batch).</li> <li>Bueno para procesos nocturnos que no tienen prisa.</li> </ul> <p>Apache Spark (El Moderno)</p> <ul> <li>Trabaja en memoria RAM (hasta 100 veces m\u00e1s r\u00e1pido).</li> <li>Permite procesamiento en tiempo real (Streaming).</li> <li>Es la evoluci\u00f3n natural de MapReduce.</li> </ul>"},{"location":"modulo2/core/#4-el-zoologico-herramientas","title":"4. El \"Zool\u00f3gico\" (Herramientas)","text":"<ul> <li>Hive: Para lanzar consultas SQL sobre Hadoop.</li> <li>Pig: Lenguaje de script para procesar datos (ETL).</li> <li>Sqoop: Mueve datos entre Hadoop y Bases de Datos SQL (Oracle, MySQL).</li> <li>Flume: Mueve datos de streaming (logs, Twitter).</li> </ul>"},{"location":"modulo2/core/#3-arquitectura-interna-la-memoria-del-namenode","title":"3. Arquitectura Interna: La Memoria del NameNode","text":"<p>El NameNode es el cerebro de Hadoop. Para no \"perder la memoria\" si se apaga, utiliza dos archivos cr\u00edticos que se guardan en el disco duro (normalmente en <code>/datos/namenode/current</code>).</p>"},{"location":"modulo2/core/#a-los-archivos-de-metadatos","title":"A. Los Archivos de Metadatos","text":"<ol> <li> <p><code>fsimage</code> (La Foto Fija):</p> <ul> <li>Es una copia completa (\"snapshot\") del estado del sistema de ficheros en un momento concreto.</li> <li>Contiene el inventario de todos los directorios y archivos.</li> <li>Analog\u00eda: Es el \"Inventario Anual\" de una biblioteca.</li> </ul> </li> <li> <p><code>edits</code> (El Diario de Cambios):</p> <ul> <li>Es un registro log de cada peque\u00f1a operaci\u00f3n que ocurre despu\u00e9s del \u00faltimo <code>fsimage</code> (crear un archivo, borrarlo, etc.).</li> <li>Analog\u00eda: Es la libreta de notas donde el bibliotecario apunta lo que pasa d\u00eda a d\u00eda .</li> </ul> </li> <li> <p><code>VERSION</code>:</p> <ul> <li>Contiene identificadores \u00fanicos como el <code>clusterID</code>. Es el \"DNI\" del cl\u00faster. Si formateas el NameNode, este ID cambia y los DataNodes dejan de reconocer al jefe.</li> </ul> </li> </ol>"},{"location":"modulo2/core/#b-el-proceso-de-checkpoint-punto-de-control","title":"B. El Proceso de Checkpoint (Punto de Control)","text":"<p>Cuando el NameNode arranca, tiene que leer el <code>fsimage</code> y aplicar todos los cambios del <code>edits</code>. Si el <code>edits</code> es gigante, el arranque es lent\u00edsimo.</p> <ul> <li>\u00bfQu\u00e9 es el Checkpoint? Es el proceso de fusionar el <code>fsimage</code> viejo + el <code>edits</code> actual para crear un nuevo <code>fsimage</code> actualizado y vaciar el registro de cambios.</li> <li>Safe Mode (Modo Seguro): Es un estado de \"solo lectura\". El cl\u00faster se pone en pausa (no se puede escribir) para realizar tareas de mantenimiento o cuando detecta problemas </li> </ul>"},{"location":"modulo2/core/#4-guia-de-operaciones-basicas-startstop","title":"4. Gu\u00eda de Operaciones B\u00e1sicas (Start/Stop)","text":"<p>Para trabajar con Hadoop, primero debemos \"levantar\" los servicios (demonios). Si no lo hacemos, recibiremos errores de <code>Connection Refused</code>.</p>"},{"location":"modulo2/core/#encender-el-cluster-hdfs","title":"\ud83d\udfe2 Encender el Cl\u00faster (HDFS)","text":"<p>Se debe ejecutar siempre que encendamos la m\u00e1quina virtual.</p> <pre><code>start-dfs.sh\n</code></pre> <ul> <li>Qu\u00e9 hace: Arranca el NameNode (maestro), los DataNodes (esclavos) y el SecondaryNameNode.</li> <li>Cu\u00e1ndo usarlo: Al inicio de la sesi\u00f3n.</li> </ul>"},{"location":"modulo2/core/#apagar-el-cluster","title":"\ud83d\udd34 Apagar el Cl\u00faster","text":"<p>Es recomendable hacerlo antes de apagar la m\u00e1quina virtual para evitar que los archivos de metadatos se corrompan.</p> <pre><code>stop-dfs.sh\n</code></pre> <ul> <li>Qu\u00e9 hace: Detiene todos los procesos de forma ordenada.</li> </ul> <p>\ud83d\udd0d Verificar el Estado (JPS) El comando jps (Java Virtual Machine Process Status Tool) es el \"m\u00e9dico\" que nos dice qu\u00e9 procesos est\u00e1n vivos.</p> <p><pre><code>jps\n</code></pre> Salida Correcta (Deben aparecer estos 3):</p> <ol> <li> <p>NameNode: El jefe. Si no est\u00e1, no funciona nada.</p> </li> <li> <p>DataNode: El trabajador. Si no est\u00e1, no tenemos d\u00f3nde guardar datos.</p> </li> <li> <p>SecondaryNameNode: El ayudante para los checkpoints.</p> </li> </ol> <p>Nota: Si al hacer jps solo sale el n\u00famero de proceso (ej: 1234 Jps) y nada m\u00e1s, significa que Hadoop est\u00e1 APAGADO.</p>"},{"location":"modulo2/practica_metadatos/","title":"Pr\u00e1ctica 2.1: Commit Manual de Metadatos","text":"<p>Esta pr\u00e1ctica tiene como objetivo entender c\u00f3mo HDFS gestiona la persistencia de los datos del NameNode (<code>fsimage</code> y <code>edits</code>) y c\u00f3mo forzar un guardado seguro.</p>"},{"location":"modulo2/practica_metadatos/#1-estado-inicial","title":"1. Estado Inicial","text":"<p>Navegamos al directorio de metadatos del NameNode para ver el estado actual.</p> <p><pre><code>cd /datos/namenode/current\nls -l\n</code></pre> Conceptos Clave:</p> <ul> <li>fsimage_...: Es una \"foto fija\" del sistema de ficheros en un momento concreto.</li> <li>edits_...: Registro de cambios (logs) ocurridos despu\u00e9s de la \u00faltima foto.</li> <li>VERSION: Contiene identificadores \u00fanicos del cl\u00faster (ClusterID, BlockPoolID).</li> </ul>"},{"location":"modulo2/practica_metadatos/#2-proceso-de-checkpoint-manual","title":"2. Proceso de Checkpoint Manual","text":""},{"location":"modulo2/practica_metadatos/#paso-a-entrar-en-modo-seguro-safe-mode","title":"Paso A: Entrar en Modo Seguro (Safe Mode)","text":"<p>Para guardar un estado consistente, debemos \"congelar\" el cl\u00faster para que nadie escriba datos nuevos.</p> <pre><code>hdfs dfsadmin -safemode enter\n</code></pre> <p>Verificaci\u00f3n: Podemos ir a la interfaz web (http://localhost:9870) y veremos que el \"Safe mode is ON\".</p>"},{"location":"modulo2/practica_metadatos/#paso-b-guardar-el-namespace-el-commit","title":"Paso B: Guardar el Namespace (El \"Commit\")","text":"<p>Este comando fuerza la uni\u00f3n de la imagen antigua + los cambios recientes (edits) para crear una imagen nueva.</p> <pre><code>hdfs dfsadmin -saveNamespace\n</code></pre> <p>Resultado: Se crea un nuevo archivo fsimage actualizado y se limpian los logs de edits.</p>"},{"location":"modulo2/practica_metadatos/#paso-c-salir-del-modo-seguro","title":"Paso C: Salir del Modo Seguro","text":"<p>Volvemos a abrir el cl\u00faster para operaciones normales.</p> <pre><code>hdfs dfsadmin -safemode leave\n</code></pre>"},{"location":"modulo2/practica_metadatos/#3-conclusiones","title":"3. Conclusiones","text":"<p>Al listar de nuevo el directorio /datos/namenode/current, observamos que:</p> <ol> <li> <p>Ha aparecido un archivo fsimage con un n\u00famero de transacci\u00f3n m\u00e1s alto.</p> </li> <li> <p>El archivo edits_inprogress se ha reiniciado.</p> </li> </ol> <p>Esto garantiza que, si el NameNode se apaga ahora mismo, el arranque ser\u00e1 mucho m\u00e1s r\u00e1pido porque ya tiene una \"foto\" reciente y no tiene que procesar miles de cambios antiguos.</p>"},{"location":"modulo3/instalacion/","title":"Instalaci\u00f3n de Hadoop","text":"<p>Nota</p> <p>Estos apuntes est\u00e1n basados en la UD 2.2 y la pr\u00e1ctica de clase.</p>"},{"location":"modulo3/instalacion/#1-requisitos-previos","title":"1. Requisitos Previos","text":"<ul> <li>Java 8: Obligatorio. Ruta t\u00edpica en mi m\u00e1quina: <code>/usr/lib/jvm/java-8-openjdk-amd64</code>.</li> <li>SSH: Debe estar configurado para acceder sin contrase\u00f1a (<code>ssh localhost</code>).</li> </ul>"},{"location":"modulo3/instalacion/#2-variables-de-entorno","title":"2. Variables de Entorno","text":"<p>A\u00f1adir al final del archivo <code>.bashrc</code>:</p> <pre><code>export HADOOP_HOME=/opt/hadoop\nexport JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\nexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\n</code></pre>"},{"location":"modulo3/instalacion/#3-configuracion-de-hadoop","title":"3. Configuraci\u00f3n de Hadoop","text":"<p>Editar el archivo hadoop-env.sh: <pre><code>export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n</code></pre></p>"},{"location":"modulo3/instalacion/#4-comandos-de-arranque","title":"4. Comandos de Arranque","text":"<p>Para levantar los demonios desde la terminal:</p> <pre><code>HDFS: start-dfs.sh\n\nYARN: start-yarn.sh (si lo usamos)\n</code></pre>"},{"location":"modulo4/yarn_mapreduce/","title":"\ud83d\udcda Apuntes: Ecosistema Hadoop (YARN &amp; MapReduce)","text":"<p>Este documento resume la evoluci\u00f3n, arquitectura y funcionamiento del procesamiento de datos en Hadoop 2.0+.</p>"},{"location":"modulo4/yarn_mapreduce/#1-evolucion-de-mapreduce-1-a-yarn","title":"1. Evoluci\u00f3n: De MapReduce 1 a YARN \ud83d\ude80","text":"<p>En la versi\u00f3n antigua de Hadoop (MR1), un solo componente (JobTracker) lo hac\u00eda todo, lo que generaba cuellos de botella al superar los 5,000 nodos. Con la llegada de YARN (Hadoop 2.0), se separaron las responsabilidades.</p>"},{"location":"modulo4/yarn_mapreduce/#tabla-comparativa-el-cambio-de-paradigma","title":"\ud83d\udd04 Tabla comparativa: El cambio de paradigma","text":"Concepto MapReduce 1 (Obsoleto) YARN (Moderno) Gesti\u00f3n JobTracker: Gestionaba recursos y monitoreaba tareas simult\u00e1neamente. ResourceManager: Solo gestiona recursos globales (CPU/RAM). Ejecuci\u00f3n TaskTracker: Ejecutaba tareas en nodos esclavos. NodeManager: Gestiona los recursos de su nodo espec\u00edfico. Recursos Slot: Huecos fijos y r\u00edgidos para tareas. Container: Paquete din\u00e1mico y abstracto de RAM y CPU. <p>\ud83d\udca1 La clave: YARN act\u00faa como el \u201cSistema Operativo\u201d del cl\u00faster, permitiendo que no solo corra MapReduce, sino tambi\u00e9n Spark o Streaming.</p>"},{"location":"modulo4/yarn_mapreduce/#2-arquitectura-de-yarn-los-3-niveles-de-mando","title":"2. Arquitectura de YARN: Los 3 niveles de mando \ud83c\udfdb\ufe0f","text":"<p>flowchart TB   RM[\ud83d\udc51 ResourceManager\\n(gestiona recursos globales)] --&gt; NM1[\ud83d\udc77 NodeManager\\n(nodo trabajador)]   RM --&gt; NM2[\ud83d\udc77 NodeManager\\n(nodo trabajador)]   RM --&gt; NM3[\ud83d\udc77 NodeManager\\n(nodo trabajador)]</p> <p>AM[\ud83c\udfbc ApplicationMaster\\n(1 por aplicaci\u00f3n)] --&gt; RM   AM --&gt; NM1   AM --&gt; NM2   AM --&gt; NM3</p> <p>NM1 --&gt; C1[\ud83d\udce6 Containers\\n(tareas)]   NM2 --&gt; C2[\ud83d\udce6 Containers\\n(tareas)]   NM3 --&gt; C3[\ud83d\udce6 Containers\\n(tareas)]</p> <p>YARN (Yet Another Resource Negotiator) gestiona el hardware del cl\u00faster mediante tres componentes principales:</p>"},{"location":"modulo4/yarn_mapreduce/#resourcemanager-el-dueno","title":"\ud83d\udc51 ResourceManager (El Due\u00f1o)","text":"<ul> <li>Ubicado en el nodo maestro.</li> <li>Tiene autoridad m\u00e1xima sobre los recursos (RAM/CPU) de todo el cl\u00faster.</li> <li>Contiene un Scheduler (planificador) que decide qui\u00e9n recibe recursos.</li> </ul>"},{"location":"modulo4/yarn_mapreduce/#nodemanager-el-capataz","title":"\ud83d\udc77 NodeManager (El Capataz)","text":"<ul> <li>Hay uno en cada nodo esclavo (trabajador).</li> <li>Vigila su propia m\u00e1quina y reporta el estado al ResourceManager.</li> <li>Crea los Contenedores donde se ejecutan las tareas finales.</li> </ul>"},{"location":"modulo4/yarn_mapreduce/#applicationmaster-el-director-de-orquesta","title":"\ud83c\udfbc ApplicationMaster (El Director de Orquesta)","text":"<ul> <li>Se crea uno por cada aplicaci\u00f3n o trabajo lanzado.</li> <li>Negocia recursos con el ResourceManager y da \u00f3rdenes a los NodeManagers.</li> <li>Desaparece en cuanto el trabajo termina.</li> </ul>"},{"location":"modulo4/yarn_mapreduce/#3-configuracion-y-administracion","title":"3. Configuraci\u00f3n y administraci\u00f3n \u2699\ufe0f","text":"<p>Para que el sistema funcione, es necesario configurar y arrancar los servicios correctamente.</p>"},{"location":"modulo4/yarn_mapreduce/#archivos-de-configuracion-etchadoop","title":"\ud83d\udcc4 Archivos de configuraci\u00f3n (<code>/etc/hadoop</code>)","text":"<ul> <li><code>mapred-site.xml</code>: Se debe especificar que el framework es yarn.</li> <li><code>yarn-site.xml</code>: Se define el hostname del ResourceManager y se activa el servicio <code>mapreduce_shuffle</code>.</li> </ul>"},{"location":"modulo4/yarn_mapreduce/#orden-de-arranque","title":"\ud83d\ude80 Orden de arranque","text":"<ol> <li>HDFS: <code>start-dfs.sh</code> (Levanta NameNode y DataNodes).</li> <li>YARN: <code>start-yarn.sh</code> (Levanta ResourceManager y NodeManagers).</li> <li>History Server (Opcional): <code>mr-jobhistory-daemon.sh start historyserver</code> </li> <li>Utilidad: Permite ver los logs de trabajos ya terminados.</li> </ol>"},{"location":"modulo4/yarn_mapreduce/#interfaz-web","title":"\ud83c\udf10 Interfaz web","text":"<p>Puedes monitorear todo en tiempo real en: <code>http://localhost:8088</code></p>"},{"location":"modulo4/yarn_mapreduce/#4-mapreduce-el-flujo-de-trabajo","title":"4. MapReduce: El flujo de trabajo \ud83d\udee0\ufe0f","text":"<p>flowchart LR   IN[\ud83d\udce5 Input (HDFS)] --&gt; MAP[\ud83d\udd0d Mapper\\n(clave, valor)]   MAP --&gt; SHUF[\ud83d\udd00 Shuffle &amp; Sort\\n(agrupa por clave)]   SHUF --&gt; RED[\ud83d\udcca Reducer\\n(operaci\u00f3n final)]   RED --&gt; OUT[\ud83d\udce4 Output (HDFS)] MapReduce es el paradigma para procesar datos en paralelo. Se divide en tres fases estrictas:</p>"},{"location":"modulo4/yarn_mapreduce/#fase-1-mapper-el-clasificador","title":"Fase 1: Mapper (El Clasificador) \ud83d\udd0d","text":"<ul> <li>Entrada: Datos en bruto (l\u00edneas de texto).</li> <li>Acci\u00f3n: Filtra y emite pares Clave-Valor (Ej: <code>pepe, 1</code>).</li> <li>Nota: No realiza c\u00e1lculos globales, solo clasifica.</li> </ul>"},{"location":"modulo4/yarn_mapreduce/#fase-2-shuffle-sort-el-organizador","title":"Fase 2: Shuffle &amp; Sort (El Organizador) \ud83d\udd00","text":"<ul> <li>Acci\u00f3n: Proceso autom\u00e1tico que recoge las salidas de los mappers, las ordena alfab\u00e9ticamente y las agrupa por clave.</li> <li>Resultado: El Reducer recibe algo como: <code>pepe, [1, 1, 1]</code>.</li> </ul>"},{"location":"modulo4/yarn_mapreduce/#fase-3-reducer-el-contador","title":"Fase 3: Reducer (El Contador) \ud83d\udcca","text":"<ul> <li>Acci\u00f3n: Itera sobre la lista de valores y realiza la operaci\u00f3n final (suma, media, etc.).</li> <li>Salida: El resultado final se guarda en HDFS.</li> </ul>"},{"location":"modulo4/yarn_mapreduce/#5-mapreduce-con-python-hadoop-streaming","title":"5. MapReduce con Python (Hadoop Streaming) \ud83d\udc0d","text":"<p>Aunque nativamente se usa Java, Hadoop Streaming permite usar Python mediante la entrada y salida est\u00e1ndar (<code>stdin/stdout</code>). Se usa principalmente por su potencia en IA y librer\u00edas de datos.</p>"},{"location":"modulo4/yarn_mapreduce/#comando-de-ejecucion-bash","title":"\ud83d\udcdd Comando de ejecuci\u00f3n (Bash)","text":"<p>```bash hadoop jar /ruta/a/hadoop-streaming.jar \\   -files mapper.py,reducer.py \\        # Env\u00eda los scripts a los nodos   -mapper mapper.py \\                  # Script para la fase Map   -reducer reducer.py \\                # Script para la fase Reduce   -input /entrada/hdfs \\               # Origen de datos   -output /salida/hdfs                 # Destino de resultados</p>"},{"location":"modulo4/yarn_mapreduce/#6-estrategias-de-ordenacion-sorting","title":"6. Estrategias de Ordenaci\u00f3n (Sorting) \ud83d\udcc9","text":"<p>MapReduce ordena por clave autom\u00e1ticamente. \u00bfPero qu\u00e9 pasa si queremos ordenar por valor (ej: ranking de palabras m\u00e1s repetidas)?</p>"},{"location":"modulo4/yarn_mapreduce/#a-ordenar-en-linux-archivos-pequenos","title":"A. Ordenar en Linux (Archivos peque\u00f1os) \ud83d\udc27","text":"<p>[cite_start]Si el resultado final es peque\u00f1o (&lt;128MB), es m\u00e1s r\u00e1pido bajarlo a local y ordenar con comandos de sistema [cite: 416-418].</p> <p>```bash hdfs dfs -cat /salida/part-* | sort -k2,2n &gt; top_usuarios.txt</p> <p>```Notas:</p> <p>-k2,2n: ordena por la segunda columna (2), trat\u00e1ndola como n\u00famero (n).</p> <p>-r: a\u00f1\u00e1delo si quieres orden inverso (descendente), por ejemplo:</p> <p>hdfs dfs -cat /salida/part-* | sort -k2,2nr &gt; top_usuarios.txt B. Ordenar en Hadoop (archivos gigantes) \ud83d\udc18</p> <p>Para Big Data real, se debe configurar el trabajo para que ordene globalmente usando comparadores espec\u00edficos.</p> <p>Requiere usar la clase KeyFieldBasedComparator.</p> <p>Se configura con opciones -D en el comando de ejecuci\u00f3n.</p> <p>Ejemplo (plantilla orientativa con -D): <code>bash hadoop jar /ruta/a/hadoop-streaming.jar \\   -D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator \\   -D mapreduce.partition.keycomparator.options=\"-k2,2nr\" \\   -files mapper.py,reducer.py \\   -mapper mapper.py \\   -reducer reducer.py \\   -input /entrada/hdfs \\   -output /salida/hdfs</code></p>"},{"location":"modulo5/practica_scheduler/","title":"Unidad 5 \u2014 Pr\u00e1ctica P5: Partici\u00f3n de Recursos por Colas en YARN (Capacity Scheduler)","text":""},{"location":"modulo5/practica_scheduler/#0-resumen","title":"0. Resumen","text":"<p>En esta pr\u00e1ctica vas a configurar el Capacity Scheduler para crear una jerarqu\u00eda de colas en YARN, repartir recursos por porcentajes, comprobar la estructura en la interfaz del ResourceManager y resolver un fallo t\u00edpico al lanzar trabajos en una cola que no es hoja.</p>"},{"location":"modulo5/practica_scheduler/#1-objetivos","title":"1. Objetivos","text":"<p>Al terminar, deber\u00edas ser capaz de:</p> <ul> <li>Definir colas principales bajo <code>root</code>.</li> <li>Crear subcolas (jerarqu\u00eda) dentro de una cola intermedia.</li> <li>Asignar capacidades coherentes (que sumen 100% en cada nivel).</li> <li>Aplicar cambios con <code>yarn rmadmin -refreshQueues</code>.</li> <li>Verificar colas y porcentajes en la UI del ResourceManager.</li> <li>Entender por qu\u00e9 solo se puede enviar jobs a colas hoja (leaf queues).</li> </ul>"},{"location":"modulo5/practica_scheduler/#2-arbol-objetivo-estructura-de-colas","title":"2. \u00c1rbol objetivo (estructura de colas)","text":"<p>La jerarqu\u00eda a implementar es:</p> <ul> <li>root</li> <li>warehouse: 20%</li> <li>datalake: 20%</li> <li>olap: 60%<ul> <li>facts: 70% (del total de <code>olap</code>)</li> <li>dimensions: 30% (del total de <code>olap</code>)</li> </ul> </li> </ul> <p>Nota: <code>facts</code> y <code>dimensions</code> son porcentajes dentro de <code>olap</code>, no del cl\u00faster completo.</p>"},{"location":"modulo5/practica_scheduler/#3-prerrequisitos","title":"3. Prerrequisitos","text":"<ul> <li>Cluster YARN funcionando (ResourceManager y NodeManagers activos).</li> <li>Acceso al directorio de configuraci\u00f3n de Hadoop:</li> <li>Normalmente: <code>$HADOOP_HOME/etc/hadoop</code></li> <li>Scheduler activo: Capacity Scheduler.</li> <li>Comprobaci\u00f3n r\u00e1pida (si hace falta):<ul> <li>Revisa <code>yarn-site.xml</code> y verifica que el scheduler sea el Capacity Scheduler (propiedad <code>yarn.resourcemanager.scheduler.class</code>).</li> </ul> </li> </ul>"},{"location":"modulo5/practica_scheduler/#4-archivo-a-editar","title":"4. Archivo a editar","text":"<p>El reparto de colas y capacidades se configura en:</p> <ul> <li><code>capacity-scheduler.xml</code></li> <li>Ruta t\u00edpica: <code>$HADOOP_HOME/etc/hadoop/capacity-scheduler.xml</code></li> </ul> <p>Consejo: antes de tocar nada, haz una copia:</p> <pre><code>cp capacity-scheduler.xml capacity-scheduler.xml.bak\n</code></pre>"},{"location":"modulo5/practica_scheduler/#5-configuracion-paso-a-paso","title":"5. Configuraci\u00f3n paso a paso","text":""},{"location":"modulo5/practica_scheduler/#paso-1-definir-las-colas-hijas-de-root","title":"PASO 1 \u2014 Definir las colas hijas de <code>root</code>","text":"<p>Busca (o a\u00f1ade) la propiedad que define las colas bajo <code>root</code> y sustituye <code>default</code> por las colas objetivo:</p> <pre><code>&lt;property&gt;\n  &lt;name&gt;yarn.scheduler.capacity.root.queues&lt;/name&gt;\n  &lt;value&gt;warehouse,datalake,olap&lt;/value&gt;\n&lt;/property&gt;\n</code></pre> <p>Importante: si exist\u00eda <code>default</code> y la quitas, aseg\u00farate de reemplazar tambi\u00e9n la configuraci\u00f3n de <code>root.default</code> por la de tus nuevas colas (para no dejar valores hu\u00e9rfanos).</p>"},{"location":"modulo5/practica_scheduler/#paso-2-asignar-capacidad-a-warehouse-datalake-y-olap","title":"PASO 2 \u2014 Asignar capacidad a <code>warehouse</code>, <code>datalake</code> y <code>olap</code>","text":"<p>A\u00f1ade (o ajusta) las propiedades de capacidad para cada cola hija de <code>root</code>.</p> <pre><code>&lt;!-- warehouse: 20% --&gt;\n&lt;property&gt;\n  &lt;name&gt;yarn.scheduler.capacity.root.warehouse.capacity&lt;/name&gt;\n  &lt;value&gt;20&lt;/value&gt;\n&lt;/property&gt;\n\n&lt;!-- datalake: 20% --&gt;\n&lt;property&gt;\n  &lt;name&gt;yarn.scheduler.capacity.root.datalake.capacity&lt;/name&gt;\n  &lt;value&gt;20&lt;/value&gt;\n&lt;/property&gt;\n\n&lt;!-- olap: 60% --&gt;\n&lt;property&gt;\n  &lt;name&gt;yarn.scheduler.capacity.root.olap.capacity&lt;/name&gt;\n  &lt;value&gt;60&lt;/value&gt;\n&lt;/property&gt;\n</code></pre> <p>\u2705 Comprobaci\u00f3n: en el nivel <code>root</code>, las capacidades deben sumar 100 (20 + 20 + 60 = 100).</p>"},{"location":"modulo5/practica_scheduler/#paso-3-convertir-olap-en-cola-padre-y-crear-facts-y-dimensions","title":"PASO 3 \u2014 Convertir <code>olap</code> en cola padre y crear <code>facts</code> y <code>dimensions</code>","text":"<p>Para que <code>olap</code> tenga subcolas, decl\u00e1ralas as\u00ed:</p> <pre><code>&lt;property&gt;\n  &lt;name&gt;yarn.scheduler.capacity.root.olap.queues&lt;/name&gt;\n  &lt;value&gt;facts,dimensions&lt;/value&gt;\n&lt;/property&gt;\n</code></pre> <p>Ahora asigna capacidades dentro de <code>olap</code> (tambi\u00e9n deben sumar 100):</p> <pre><code>&lt;!-- facts: 70% de la capacidad de olap --&gt;\n&lt;property&gt;\n  &lt;name&gt;yarn.scheduler.capacity.root.olap.facts.capacity&lt;/name&gt;\n  &lt;value&gt;70&lt;/value&gt;\n&lt;/property&gt;\n\n&lt;!-- dimensions: 30% de la capacidad de olap --&gt;\n&lt;property&gt;\n  &lt;name&gt;yarn.scheduler.capacity.root.olap.dimensions.capacity&lt;/name&gt;\n  &lt;value&gt;30&lt;/value&gt;\n&lt;/property&gt;\n</code></pre> <p>Resultado: <code>facts</code> y <code>dimensions</code> son colas hoja, y <code>olap</code> deja de ser una cola hoja (pasa a ser padre).</p>"},{"location":"modulo5/practica_scheduler/#paso-4-opcional-recomendado-estado-y-maximos-de-capacidad","title":"PASO 4 \u2014 (Opcional recomendado) Estado y m\u00e1ximos de capacidad","text":"<p>Para evitar sorpresas, puedes marcar colas como activas y limitar o ampliar su m\u00e1ximo.</p> <p>Estado por defecto: <pre><code>&lt;property&gt;\n  &lt;name&gt;yarn.scheduler.capacity.root.olap.facts.state&lt;/name&gt;\n  &lt;value&gt;RUNNING&lt;/value&gt;\n&lt;/property&gt;\n</code></pre></p> <p>Capacidad m\u00e1xima (porcentaje): <pre><code>&lt;property&gt;\n  &lt;name&gt;yarn.scheduler.capacity.root.olap.facts.maximum-capacity&lt;/name&gt;\n  &lt;value&gt;100&lt;/value&gt;\n&lt;/property&gt;\n</code></pre></p> <p><code>maximum-capacity</code> controla hasta d\u00f3nde puede \u201cestirarse\u201d una cola si las dem\u00e1s est\u00e1n vac\u00edas (seg\u00fan configuraci\u00f3n y demanda).</p>"},{"location":"modulo5/practica_scheduler/#6-aplicar-cambios-y-verificar","title":"6. Aplicar cambios y verificar","text":""},{"location":"modulo5/practica_scheduler/#61-recargar-colas-sin-reiniciar-servicios","title":"6.1 Recargar colas (sin reiniciar servicios)","text":"<p>Una vez guardado el archivo:</p> <pre><code>yarn rmadmin -refreshQueues\n</code></pre> <p>Si por alguna raz\u00f3n la UI no refleja cambios, un reinicio del ResourceManager puede ser necesario (depende de c\u00f3mo est\u00e9 gestionado el cl\u00faster).</p>"},{"location":"modulo5/practica_scheduler/#62-verificacion-en-la-ui","title":"6.2 Verificaci\u00f3n en la UI","text":"<p>En la web del ResourceManager (t\u00edpicamente puerto <code>8088</code>):</p> <ul> <li>Revisa la secci\u00f3n del Scheduler y comprueba:</li> <li>Que existen <code>warehouse</code>, <code>datalake</code>, <code>olap</code>.</li> <li>Que dentro de <code>olap</code> existen <code>facts</code> y <code>dimensions</code>.</li> <li>Que los porcentajes coinciden con lo esperado.</li> </ul>"},{"location":"modulo5/practica_scheduler/#7-tabla-de-capacidades-globales-respecto-al-cluster-total","title":"7. Tabla de capacidades globales (respecto al cl\u00faster total)","text":"<p>Aunque <code>facts</code> y <code>dimensions</code> se configuran dentro de <code>olap</code>, su capacidad real sobre el cl\u00faster es:</p> Cola Capacidad respecto al cl\u00faster C\u00e1lculo <code>warehouse</code> 20% asignaci\u00f3n directa <code>datalake</code> 20% asignaci\u00f3n directa <code>facts</code> 42% 70% de 60% \u2192 0.70 \u00d7 60 = 42 <code>dimensions</code> 18% 30% de 60% \u2192 0.30 \u00d7 60 = 18 <p>\u2705 Comprobaci\u00f3n final: 20 + 20 + 42 + 18 = 100.</p>"},{"location":"modulo5/practica_scheduler/#8-ejecucion-de-wordcount-y-resolucion-de-error","title":"8. Ejecuci\u00f3n de WordCount y resoluci\u00f3n de error","text":""},{"location":"modulo5/practica_scheduler/#81-el-problema-job-enviado-a-una-cola-que-no-es-hoja","title":"8.1 El problema: job enviado a una cola que no es hoja","text":"<p>Si lanzas el trabajo indicando la cola <code>olap</code>:</p> <pre><code>hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.4.2.jar wordcount   -Dmapreduce.job.queuename=olap   /input/documento.txt /output/output_olap\n</code></pre> <p>Resultado esperado: el job falla (FAILED).</p> <p>Explicaci\u00f3n: - En Capacity Scheduler, solo se pueden enviar trabajos a colas hoja. - <code>olap</code> no es hoja porque tiene hijas: <code>facts</code> y <code>dimensions</code>. - Por tanto, YARN rechaza el env\u00edo.</p>"},{"location":"modulo5/practica_scheduler/#82-la-solucion-enviar-el-job-a-una-cola-hoja","title":"8.2 La soluci\u00f3n: enviar el job a una cola hoja","text":"<p>Por ejemplo a <code>facts</code>:</p> <pre><code>hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.4.2.jar wordcount   -Dmapreduce.job.queuename=facts   /input/documento.txt /output/output_facts\n</code></pre> <p>Verificaci\u00f3n: - En la UI del ResourceManager, el job deber\u00eda aparecer como SUCCEEDED. - Comprueba tambi\u00e9n que el consumo de recursos se refleja en la cola correcta.</p>"},{"location":"modulo5/practica_scheduler/#9-cuestionario-respuestas","title":"9. Cuestionario (respuestas)","text":"<p>1) \u00bfQu\u00e9 variable XML gestiona la capacidad m\u00e1xima de una cola? <code>yarn.scheduler.capacity.&lt;ruta_cola&gt;.maximum-capacity</code> Ejemplo en <code>facts</code>: <code>yarn.scheduler.capacity.root.olap.facts.maximum-capacity</code></p> <p>2) \u00bfQu\u00e9 variable XML indica el estado por defecto de una cola? <code>yarn.scheduler.capacity.&lt;ruta_cola&gt;.state</code> Valores t\u00edpicos: <code>RUNNING</code> (activa) / <code>STOPPED</code> (detenida)</p> <p>3) \u00bfQu\u00e9 variable gestiona la vida m\u00e1xima de un proceso? <code>yarn.scheduler.capacity.&lt;ruta_cola&gt;.maximum-application-lifetime</code> - Para deshabilitar (sin l\u00edmite): <code>-1</code> - Para limitar a 10 minutos: <code>600</code> (segundos)</p>"},{"location":"modulo5/practica_scheduler/#10-entrega-sugerida","title":"10. Entrega sugerida","text":"<p>Incluye en tu entrega:</p> <ul> <li>Captura o evidencia del \u00e1rbol de colas en la UI.</li> <li>Fragmento relevante de <code>capacity-scheduler.xml</code> (colas y capacidades).</li> <li>Evidencia de:</li> <li>Job fallando al usar <code>olap</code> como cola.</li> <li>Job funcionando al usar <code>facts</code> o <code>dimensions</code>.</li> </ul>"},{"location":"modulo5/practica_scheduler/#11-referencias-de-apuntes-marcadores","title":"11. Referencias de apuntes (marcadores)","text":"<p>[^273]: Marcador de referencia: 273\u2013274 [^275]: Marcador de referencia: 275\u2013276 [^277]: Marcador de referencia: 277 [^278]: Marcador de referencia: 278 [^279]: Marcador de referencia: 279 [^280]: Marcador de referencia: 280 [^281]: Marcador de referencia: 281 [^282]: Marcador de referencia: 282 [^285]: Marcador de referencia: 285\u2013286 [^321]: Marcador de referencia: 321\u2013322</p>"},{"location":"modulo5/yarn_scheduler/","title":"UD 5: YARN Scheduler","text":"<p>Asignatura: Grado de Especializaci\u00f3n Big Data e IA </p>"},{"location":"modulo5/yarn_scheduler/#1-introduccion-al-scheduler-de-yarn","title":"1. Introducci\u00f3n al Scheduler de YARN","text":"<p>El Scheduler es el componente de YARN responsable de la partici\u00f3n de los recursos de todo el cl\u00faster y de la asignaci\u00f3n de procesos a cada una de esas particiones.</p>"},{"location":"modulo5/yarn_scheduler/#evolucion-historica","title":"Evoluci\u00f3n Hist\u00f3rica","text":"<ul> <li>MapReduce 1 (MR1): La distribuci\u00f3n de recursos era homog\u00e9nea para todo el cl\u00faster. Se utilizaba el Fair Scheduler, el cual no permit\u00eda realizar particiones de recursos de forma jer\u00e1rquica.</li> <li>YARN: Implementa una gesti\u00f3n de recursos basada en una estructura de \u00e1rbol. Este modelo se conoce como Capacity Scheduler.</li> </ul>"},{"location":"modulo5/yarn_scheduler/#2-interfaz-de-usuario-y-monitorizacion","title":"2. Interfaz de Usuario y Monitorizaci\u00f3n","text":"<p>Es posible supervisar la gesti\u00f3n de recursos a trav\u00e9s de la interfaz web de YARN.</p>"},{"location":"modulo5/yarn_scheduler/#metricas-de-configuracion-scheduler-metrics","title":"M\u00e9tricas de Configuraci\u00f3n (Scheduler Metrics)","text":"<p>En la interfaz podemos observar l\u00edmites cr\u00edticos para el funcionamiento del cl\u00faster: * Minimum Allocation: El recurso m\u00ednimo que se asigna a cada contenedor (ejemplo: <code>&lt;memory:1024, vCores:1&gt;</code>). * Maximum Allocation: El l\u00edmite m\u00e1ximo de recursos que puede solicitar un solo proceso (ejemplo: <code>&lt;memory:8192, vCores:4&gt;</code>).</p>"},{"location":"modulo5/yarn_scheduler/#jerarquia-por-defecto","title":"Jerarqu\u00eda por Defecto","text":"<p>Si no se realiza una configuraci\u00f3n espec\u00edfica, YARN crea autom\u00e1ticamente: 1.  Una cola general llamada root. 2.  Una subcola llamada default, que tiene asignado el 100% de los recursos del cl\u00faster.</p>"},{"location":"modulo5/yarn_scheduler/#3-configuracion-capacity-schedulerxml","title":"3. Configuraci\u00f3n: <code>capacity-scheduler.xml</code>","text":"<p>La distribuci\u00f3n de recursos en forma de \"colas\" se define en el archivo de configuraci\u00f3n <code>capacity-scheduler.xml</code>. Este archivo se encuentra junto al resto de archivos de configuraci\u00f3n de Hadoop.</p>"},{"location":"modulo5/yarn_scheduler/#propiedades-principales","title":"Propiedades Principales","text":"<ol> <li>Definici\u00f3n de colas (<code>queues</code>): Indica qu\u00e9 colas existen en un nivel determinado.<ul> <li>Ejemplo: <code>yarn.scheduler.capacity.root.queues</code> con valor <code>default, prod, desa</code> crear\u00e1 tres colas que cuelgan del nodo ra\u00edz.</li> </ul> </li> <li>Asignaci\u00f3n de Capacidad (<code>capacity</code>): Indica el porcentaje de recursos asignado a cada cola.<ul> <li>Ejemplo: <code>yarn.scheduler.capacity.root.default.capacity</code> con valor <code>30</code> asigna el 30% a esa cola.</li> </ul> </li> </ol> <p>Nota: Para a\u00f1adir elementos a un nivel, los nombres de las colas se separan por comas en la configuraci\u00f3n.</p>"},{"location":"modulo5/yarn_scheduler/#4-gestion-de-recursos-y-colas","title":"4. Gesti\u00f3n de Recursos y Colas","text":"<p>Una vez modificado el archivo de configuraci\u00f3n, existen dos formas de aplicar los cambios:</p> <ol> <li>Reinicio del servicio: Parar y arrancar Hadoop.</li> <li>Refresco en caliente: Ejecutar el comando <code>yarn rmadmin -refreshQueues</code>.<ul> <li>Riesgos: Este comando puede fallar si la cola est\u00e1 en uso (estado <code>RUNNING</code>), especialmente si intentas convertir una cola de tipo \"hoja\" en una cola \"padre\".</li> </ul> </li> </ol>"},{"location":"modulo5/yarn_scheduler/#5-asignacion-de-procesos-a-colas","title":"5. Asignaci\u00f3n de Procesos a Colas","text":"<p>Para ejecutar un trabajo de MapReduce en una cola espec\u00edfica (distinta a la <code>default</code>), se debe a\u00f1adir un par\u00e1metro en la l\u00ednea de comandos:</p> <p>Par\u00e1metro: <code>-Dmapreduce.job.queuename=nombre_de_la_cola</code> </p> <p>Ejemplo de ejecuci\u00f3n: <pre><code>hadoop jar hadoop-mapreduce-examples.jar wordcount -Dmapreduce.job.queuename=facts/libros /entrada /salida\n</code></pre></p>"},{"location":"modulo5/yarn_scheduler/#6-resumen-de-comandos-utiles","title":"6. Resumen de Comandos \u00datiles","text":"<ul> <li>Listar colas por consola: <code>mapred queue -list</code>.</li> <li>Actualizar configuraci\u00f3n sin reiniciar: <code>yarn rmadmin -refreshQueues</code>.</li> </ul>"}]}