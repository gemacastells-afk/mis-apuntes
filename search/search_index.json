{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Mis Apuntes de Big Data","text":"<p>Bienvenido a mi wiki personal. Aqu\u00ed ir\u00e9 subiendo todo lo que aprenda sobre Hadoop, Spark y el ecosistema Big Data.</p>"},{"location":"#estructura-del-curso","title":"Estructura del curso","text":"<p>Haz clic en los enlaces para ir a cada tema:</p> <ul> <li>M\u00f3dulo 1: Teor\u00eda y Fundamentos</li> <li>M\u00f3dulo 2: Ecosistema Hadoop</li> <li>M\u00f3dulo 3: Instalaci\u00f3n y Pr\u00e1ctica</li> <li>M\u00f3dulo 4: YARN y MapReduce</li> </ul>"},{"location":"modulo1/chuleta/","title":"\ud83d\uddfa\ufe0f Mapa Mental: Linux vs. HDFS","text":"<p>Es vital diferenciar d\u00f3nde estamos trabajando. Tenemos dos sistemas de archivos paralelos que no se tocan directamente.</p>"},{"location":"modulo1/chuleta/#1-los-dos-universos","title":"1. Los Dos Universos","text":"Universo Linux Local (Tu PC) Hadoop (HDFS) \u00bfQu\u00e9 es? El disco duro f\u00edsico de tu m\u00e1quina virtual. Un sistema virtual repartido entre muchos nodos. \u00bfC\u00f3mo empiezo? Comandos normales (<code>ls</code>, <code>cd</code>). Siempre empieza por <code>hdfs dfs ...</code> \u00bfPuedo entrar (<code>cd</code>)? \u2705 S\u00ed. Te mueves por las carpetas. \u274c NO. No puedes \"entrar\". Solo puedes listar desde fuera."},{"location":"modulo1/chuleta/#2-diccionario-de-traduccion","title":"2. Diccionario de Traducci\u00f3n","text":"<p>Si quieres hacer algo en Hadoop, busca su equivalente:</p> Acci\u00f3n En Linux (Local) En Hadoop (HDFS) Listar archivos <code>ls -l</code> <code>hdfs dfs -ls /ruta</code> Crear carpeta <code>mkdir carpeta</code> <code>hdfs dfs -mkdir /ruta/carpeta</code> Borrar archivo <code>rm archivo</code> <code>hdfs dfs -rm /ruta/archivo</code> Ver contenido <code>cat archivo</code> <code>hdfs dfs -cat /ruta/archivo</code> Cambiar permisos <code>chmod 777</code> <code>hdfs dfs -chmod 777 /ruta</code>"},{"location":"modulo1/chuleta/#3-el-puente-subir-y-bajar-datos","title":"3. El \"Puente\" (Subir y Bajar datos)","text":"<p>Como son dos mundos separados, necesitamos comandos para mover archivos de uno a otro.</p> <ul> <li> <p>Subir (De Linux \u27a1 HDFS):</p> <ul> <li><code>put</code>: <code>hdfs dfs -put mi_foto.jpg /fotos</code></li> <li>(Significa: \"Coge mi_foto.jpg de aqu\u00ed y ponla en la carpeta /fotos de Hadoop\")</li> </ul> </li> <li> <p>Bajar (De HDFS \u27a1 Linux):</p> <ul> <li><code>get</code>: <code>hdfs dfs -get /fotos/mi_foto.jpg .</code></li> <li>(Significa: \"Trae la foto de Hadoop y d\u00e9jala aqu\u00ed mismo en mi Linux\")</li> </ul> </li> </ul>"},{"location":"modulo1/intro/","title":"Introducci\u00f3n al Big Data","text":""},{"location":"modulo1/intro/#1-que-es-big-data","title":"1. \u00bfQu\u00e9 es Big Data?","text":"<p>No es solo \"muchos datos\". Es el tratamiento y an\u00e1lisis de enormes repositorios de datos que son tan desproporcionadamente grandes que resulta imposible tratarlos con las herramientas de bases de datos y anal\u00edticas convencionales.</p> <p>Regla de Oro</p> <p>Si tus datos caben en una hoja de Excel o en una base de datos SQL tradicional y el tiempo de respuesta es aceptable, NO necesitas Big Data.</p>"},{"location":"modulo1/intro/#2-las-5-v-del-big-data","title":"2. Las 5 V del Big Data","text":"<p>Para que un problema se considere Big Data, suele cumplir estas caracter\u00edsticas:</p> <ul> <li>Volumen: La cantidad de datos (Terabytes, Petabytes...).</li> <li>Velocidad: La rapidez con la que se generan y procesan los datos (ej. sensores, streaming).</li> <li>Variedad: Distintos formatos. No solo texto, tambi\u00e9n video, audio, logs, redes sociales.</li> <li>Veracidad: La calidad y fiabilidad del dato (limpiar el \"ruido\").</li> <li>Valor: La capacidad de convertir esos datos en dinero o decisiones \u00fatiles.</li> </ul>"},{"location":"modulo1/intro/#3-tipos-de-datos","title":"3. Tipos de Datos","text":"Tipo Descripci\u00f3n Ejemplo Estructurados Tienen formato fijo y definido. Tablas SQL, Excel, CSV. No Estructurados No tienen estructura interna clara. V\u00eddeo, Audio, PDF, Emails. Semi-estructurados Tienen etiquetas pero no esquema r\u00edgido. HTML, XML, JSON."},{"location":"modulo1/practica/","title":"Pr\u00e1ctica Unidad 1: Instalaci\u00f3n de Hadoop","text":"<p>Esta p\u00e1gina documenta la entrega de la pr\u00e1ctica de la Unidad 1, detallando el proceso de instalaci\u00f3n base de Hadoop en modo Pseudo-distribuido.</p>"},{"location":"modulo1/practica/#objetivos-de-la-practica","title":"\ud83c\udfaf Objetivos de la Pr\u00e1ctica","text":"<p>Realizar una instalaci\u00f3n funcional que cumpla con los siguientes requisitos: 1.  C\u00f3digo fuente: Ubicado en <code>/opt/hadoop</code>. 2.  Java: Instalaci\u00f3n de JDK8 (Open o Privado). 3.  SSH: Instalaci\u00f3n y configuraci\u00f3n para acceso sin contrase\u00f1a. 4.  Variables de Entorno: Configuraci\u00f3n para ejecutar comandos desde cualquier ruta.</p>"},{"location":"modulo1/practica/#desarrollo-de-la-instalacion","title":"\ud83d\udee0\ufe0f Desarrollo de la Instalaci\u00f3n","text":""},{"location":"modulo1/practica/#1-despliegue-del-codigo-fuente","title":"1. Despliegue del C\u00f3digo Fuente","text":"<p>Se ha descargado y descomprimido Hadoop en el directorio est\u00e1ndar de Linux para software opcional.</p> <ul> <li>Ruta de instalaci\u00f3n: <code>/opt/hadoop</code></li> <li>Permisos: El usuario actual es propietario de la carpeta.</li> </ul> <pre><code># Verificaci\u00f3n\nls -ld /opt/hadoop\n</code></pre>"},{"location":"modulo1/practica/#2-instalacion-de-java-jdk-8","title":"2. Instalaci\u00f3n de Java (JDK 8)","text":"<p>Hadoop requiere Java 8 para funcionar correctamente. Se ha instalado openjdk-8-jdk <pre><code># Verificaci\u00f3n de versi\u00f3n\njava -version\n# Salida esperada: openjdk version \"1.8.0_...\"\n</code></pre></p>"},{"location":"modulo1/practica/#3-configuracion-ssh","title":"3. Configuraci\u00f3n SSH","text":"<p>Para que los scripts de arranque (start-dfs.sh, start-yarn.sh) funcionen, el nodo debe poder conectarse a s\u00ed mismo sin pedir contrase\u00f1a.</p> <ul> <li> <p>Clave generada con: ssh-keygen -t rsa</p> <ul> <li>Clave copiada con: ssh-copy-id localhost</li> </ul> </li> </ul> <pre><code># Prueba de conexi\u00f3n (no debe pedir password)\nssh localhost\n</code></pre>"},{"location":"modulo1/practica/#4-variables-de-entorno-bashrc","title":"4. Variables de Entorno (.bashrc)","text":"<p>Se han a\u00f1adido las rutas al archivo .bashrc para que el sistema reconozca los comandos de Hadoop globalmente.</p> <p>Configuraci\u00f3n aplicada:</p> <pre><code>export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\nexport HADOOP_HOME=/opt/hadoop\nexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\n</code></pre> <p>Verificaci\u00f3n:</p> <pre><code># Ejecutado desde la carpeta HOME (~)\nhadoop version\n</code></pre>"},{"location":"modulo2/core/","title":"El Ecosistema Hadoop","text":""},{"location":"modulo2/core/#1-arquitectura-maestro-esclavo","title":"1. Arquitectura: Maestro - Esclavo","text":"<p>Hadoop funciona como un ej\u00e9rcito. Un nodo manda y los dem\u00e1s obedecen.</p> <ul> <li>Master (Maestro): Gestiona, coordina y sabe d\u00f3nde est\u00e1 todo.</li> <li>Slave (Esclavo): Hace el trabajo sucio (guardar datos o procesar c\u00e1lculos).</li> <li>Commodity Hardware: Hadoop est\u00e1 dise\u00f1ado para ejecutarse en ordenadores \"baratos\" y normales, no en superordenadores.</li> </ul>"},{"location":"modulo2/core/#2-los-dos-pilares-de-hadoop","title":"2. Los Dos Pilares de Hadoop","text":""},{"location":"modulo2/core/#a-hdfs-almacenamiento","title":"A. HDFS (Almacenamiento)","text":"<p>Es el sistema de archivos distribuido. Rompe los archivos en bloques y los reparte. * NameNode (Maestro): El \u00edndice. Sabe en qu\u00e9 nodo est\u00e1 cada trozo de archivo. * DataNode (Esclavo): El almac\u00e9n. Guarda los bloques de datos f\u00edsicamente. * Replicaci\u00f3n: Por defecto, cada bloque se guarda 3 veces en distintos nodos para evitar p\u00e9rdidas si un disco se rompe.</p>"},{"location":"modulo2/core/#b-yarn-procesamiento","title":"B. YARN (Procesamiento)","text":"<p>Es el sistema operativo del cl\u00faster. Reparte la RAM y la CPU. * ResourceManager (Maestro): Decide cu\u00e1ntos recursos le da a cada tarea. * NodeManager (Esclavo): Vigila el uso de CPU/RAM en cada m\u00e1quina.</p>"},{"location":"modulo2/core/#3-mapreduce-vs-spark","title":"3. MapReduce vs Spark","text":"<p>Son las formas de \"trabajar\" con los datos.</p> <p>MapReduce (El Cl\u00e1sico)</p> <ul> <li>Trabaja escribiendo mucho en disco duro.</li> <li>Es lento y por lotes (Batch).</li> <li>Bueno para procesos nocturnos que no tienen prisa.</li> </ul> <p>Apache Spark (El Moderno)</p> <ul> <li>Trabaja en memoria RAM (hasta 100 veces m\u00e1s r\u00e1pido).</li> <li>Permite procesamiento en tiempo real (Streaming).</li> <li>Es la evoluci\u00f3n natural de MapReduce.</li> </ul>"},{"location":"modulo2/core/#4-el-zoologico-herramientas","title":"4. El \"Zool\u00f3gico\" (Herramientas)","text":"<ul> <li>Hive: Para lanzar consultas SQL sobre Hadoop.</li> <li>Pig: Lenguaje de script para procesar datos (ETL).</li> <li>Sqoop: Mueve datos entre Hadoop y Bases de Datos SQL (Oracle, MySQL).</li> <li>Flume: Mueve datos de streaming (logs, Twitter).</li> </ul>"},{"location":"modulo2/core/#3-arquitectura-interna-la-memoria-del-namenode","title":"3. Arquitectura Interna: La Memoria del NameNode","text":"<p>El NameNode es el cerebro de Hadoop. Para no \"perder la memoria\" si se apaga, utiliza dos archivos cr\u00edticos que se guardan en el disco duro (normalmente en <code>/datos/namenode/current</code>).</p>"},{"location":"modulo2/core/#a-los-archivos-de-metadatos","title":"A. Los Archivos de Metadatos","text":"<ol> <li> <p><code>fsimage</code> (La Foto Fija):</p> <ul> <li>Es una copia completa (\"snapshot\") del estado del sistema de ficheros en un momento concreto.</li> <li>Contiene el inventario de todos los directorios y archivos.</li> <li>Analog\u00eda: Es el \"Inventario Anual\" de una biblioteca [cite: 28-29].</li> </ul> </li> <li> <p><code>edits</code> (El Diario de Cambios):</p> <ul> <li>Es un registro log de cada peque\u00f1a operaci\u00f3n que ocurre despu\u00e9s del \u00faltimo <code>fsimage</code> (crear un archivo, borrarlo, etc.).</li> <li>Analog\u00eda: Es la libreta de notas donde el bibliotecario apunta lo que pasa d\u00eda a d\u00eda .</li> </ul> </li> <li> <p><code>VERSION</code>:</p> <ul> <li>Contiene identificadores \u00fanicos como el <code>clusterID</code>. Es el \"DNI\" del cl\u00faster. Si formateas el NameNode, este ID cambia y los DataNodes dejan de reconocer al jefe [cite: 33-34, 47].</li> </ul> </li> </ol>"},{"location":"modulo2/core/#b-el-proceso-de-checkpoint-punto-de-control","title":"B. El Proceso de Checkpoint (Punto de Control)","text":"<p>Cuando el NameNode arranca, tiene que leer el <code>fsimage</code> y aplicar todos los cambios del <code>edits</code>. Si el <code>edits</code> es gigante, el arranque es lent\u00edsimo.</p> <ul> <li>\u00bfQu\u00e9 es el Checkpoint? Es el proceso de fusionar el <code>fsimage</code> viejo + el <code>edits</code> actual para crear un nuevo <code>fsimage</code> actualizado y vaciar el registro de cambios.</li> <li>Safe Mode (Modo Seguro): Es un estado de \"solo lectura\". El cl\u00faster se pone en pausa (no se puede escribir) para realizar tareas de mantenimiento o cuando detecta problemas </li> </ul>"},{"location":"modulo2/core/#4-guia-de-operaciones-basicas-startstop","title":"4. Gu\u00eda de Operaciones B\u00e1sicas (Start/Stop)","text":"<p>Para trabajar con Hadoop, primero debemos \"levantar\" los servicios (demonios). Si no lo hacemos, recibiremos errores de <code>Connection Refused</code>.</p>"},{"location":"modulo2/core/#encender-el-cluster-hdfs","title":"\ud83d\udfe2 Encender el Cl\u00faster (HDFS)","text":"<p>Se debe ejecutar siempre que encendamos la m\u00e1quina virtual.</p> <p><pre><code>start-dfs.sh\n</code></pre> * Qu\u00e9 hace: Arranca el NameNode (maestro), los DataNodes (esclavos) y el SecondaryNameNode.</p> <ul> <li>Cu\u00e1ndo usarlo: Al inicio de la sesi\u00f3n.</li> </ul>"},{"location":"modulo2/core/#apagar-el-cluster","title":"\ud83d\udd34 Apagar el Cl\u00faster","text":"<p>Es recomendable hacerlo antes de apagar la m\u00e1quina virtual para evitar que los archivos de metadatos se corrompan.</p> <pre><code>stop-dfs.sh\n</code></pre> <ul> <li>Qu\u00e9 hace: Detiene todos los procesos de forma ordenada.</li> </ul> <p>\ud83d\udd0d Verificar el Estado (JPS) El comando jps (Java Virtual Machine Process Status Tool) es el \"m\u00e9dico\" que nos dice qu\u00e9 procesos est\u00e1n vivos.</p> <p><pre><code>jps\n</code></pre> Salida Correcta (Deben aparecer estos 3):</p> <ol> <li> <p>NameNode: El jefe. Si no est\u00e1, no funciona nada.</p> </li> <li> <p>DataNode: El trabajador. Si no est\u00e1, no tenemos d\u00f3nde guardar datos.</p> </li> <li> <p>SecondaryNameNode: El ayudante para los checkpoints.</p> </li> </ol> <p>Nota: Si al hacer jps solo sale el n\u00famero de proceso (ej: 1234 Jps) y nada m\u00e1s, significa que Hadoop est\u00e1 APAGADO.</p>"},{"location":"modulo2/practica_metadatos/","title":"Pr\u00e1ctica 2.1: Commit Manual de Metadatos","text":"<p>Esta pr\u00e1ctica tiene como objetivo entender c\u00f3mo HDFS gestiona la persistencia de los datos del NameNode (<code>fsimage</code> y <code>edits</code>) y c\u00f3mo forzar un guardado seguro.</p>"},{"location":"modulo2/practica_metadatos/#1-estado-inicial","title":"1. Estado Inicial","text":"<p>Navegamos al directorio de metadatos del NameNode para ver el estado actual.</p> <p><pre><code>cd /datos/namenode/current\nls -l\n</code></pre> Conceptos Clave:</p> <pre><code>- fsimage_...: Es una \"foto fija\" del sistema de ficheros en un momento concreto.\n\n- edits_...: Registro de cambios (logs) ocurridos despu\u00e9s de la \u00faltima foto.\n\n- VERSION: Contiene identificadores \u00fanicos del cl\u00faster (ClusterID, BlockPoolID).\n</code></pre>"},{"location":"modulo2/practica_metadatos/#2-proceso-de-checkpoint-manual","title":"2. Proceso de Checkpoint Manual","text":""},{"location":"modulo2/practica_metadatos/#paso-a-entrar-en-modo-seguro-safe-mode","title":"Paso A: Entrar en Modo Seguro (Safe Mode)","text":"<p>Para guardar un estado consistente, debemos \"congelar\" el cl\u00faster para que nadie escriba datos nuevos.</p> <pre><code>hdfs dfsadmin -safemode enter\n</code></pre> <pre><code>Verificaci\u00f3n: Podemos ir a la interfaz web (http://localhost:9870) y veremos que el \"Safe mode is ON\".\n</code></pre>"},{"location":"modulo2/practica_metadatos/#paso-b-guardar-el-namespace-el-commit","title":"Paso B: Guardar el Namespace (El \"Commit\")","text":"<p>Este comando fuerza la uni\u00f3n de la imagen antigua + los cambios recientes (edits) para crear una imagen nueva.</p> <pre><code>hdfs dfsadmin -saveNamespace\n</code></pre> <p>Resultado: Se crea un nuevo archivo fsimage actualizado y se limpian los logs de edits.</p>"},{"location":"modulo2/practica_metadatos/#paso-c-salir-del-modo-seguro","title":"Paso C: Salir del Modo Seguro","text":"<p>Volvemos a abrir el cl\u00faster para operaciones normales.</p> <pre><code>hdfs dfsadmin -safemode leave\n</code></pre>"},{"location":"modulo2/practica_metadatos/#3-conclusiones","title":"3. Conclusiones","text":"<p>Al listar de nuevo el directorio /datos/namenode/current, observamos que:</p> <pre><code>1. Ha aparecido un archivo fsimage con un n\u00famero de transacci\u00f3n m\u00e1s alto.\n\n2. El archivo edits_inprogress se ha reiniciado.\n</code></pre> <p>Esto garantiza que, si el NameNode se apaga ahora mismo, el arranque ser\u00e1 mucho m\u00e1s r\u00e1pido porque ya tiene una \"foto\" reciente y no tiene que procesar miles de cambios antiguos.</p>"},{"location":"modulo3/instalacion/","title":"Instalaci\u00f3n de Hadoop","text":"<p>Nota</p> <p>Estos apuntes est\u00e1n basados en la UD 2.2 y la pr\u00e1ctica de clase.</p>"},{"location":"modulo3/instalacion/#1-requisitos-previos","title":"1. Requisitos Previos","text":"<ul> <li>Java 8: Obligatorio. Ruta t\u00edpica en mi m\u00e1quina: <code>/usr/lib/jvm/java-8-openjdk-amd64</code>.</li> <li>SSH: Debe estar configurado para acceder sin contrase\u00f1a (<code>ssh localhost</code>).</li> </ul>"},{"location":"modulo3/instalacion/#2-variables-de-entorno","title":"2. Variables de Entorno","text":"<p>A\u00f1adir al final del archivo <code>.bashrc</code>:</p> <pre><code>export HADOOP_HOME=/opt/hadoop\nexport JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\nexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\n</code></pre>"},{"location":"modulo3/instalacion/#3-configuracion-de-hadoop","title":"3. Configuraci\u00f3n de Hadoop","text":"<p>Editar el archivo hadoop-env.sh: <pre><code>export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n</code></pre></p>"},{"location":"modulo3/instalacion/#4-comandos-de-arranque","title":"4. Comandos de Arranque","text":"<p>Para levantar los demonios desde la terminal:</p> <pre><code>HDFS: start-dfs.sh\n\nYARN: start-yarn.sh (si lo usamos)\n</code></pre>"},{"location":"modulo4/yarn_mapreduce/","title":"YARN y MapReduce","text":""},{"location":"modulo4/yarn_mapreduce/#1-evolucion-de-hadoop-10-a-20","title":"1. Evoluci\u00f3n: De Hadoop 1.0 a 2.0","text":"<p>Antes de entender c\u00f3mo funciona hoy, hay que entender el problema del pasado.</p>"},{"location":"modulo4/yarn_mapreduce/#el-problema-de-hadoop-10-mr1","title":"El Problema de Hadoop 1.0 (MR1)","text":"<p>[cite_start]En la versi\u00f3n antigua, exist\u00eda un \u00fanico \"dictador\" llamado JobTracker [cite: 271-272]. Este componente ten\u00eda que hacerlo todo: 1.  Gestionar recursos: Decidir qu\u00e9 ordenadores ten\u00edan memoria libre. 2.  Controlar tareas: Vigilar que el c\u00f3digo no fallara.</p> <p>Esto creaba un cuello de botella. Si el cl\u00faster crec\u00eda a miles de ordenadores, el JobTracker colapsaba. Adem\u00e1s, solo permit\u00eda ejecutar trabajos de tipo MapReduce (nada de Spark o streaming).</p>"},{"location":"modulo4/yarn_mapreduce/#la-solucion-hadoop-20-yarn","title":"La Soluci\u00f3n: Hadoop 2.0 (YARN)","text":"<p>La soluci\u00f3n fue dividir responsabilidades. [cite_start]Nace YARN (Yet Another Resource Negotiator), que act\u00faa como el Sistema Operativo del cl\u00faster [cite: 260-267]. * YARN solo gestiona el hardware (RAM/CPU). * Las aplicaciones (como MapReduce o Spark) se ejecutan encima de YARN como si fueran programas instalados.</p>"},{"location":"modulo4/yarn_mapreduce/#2-arquitectura-de-yarn","title":"2. Arquitectura de YARN","text":"<p>YARN funciona con una jerarqu\u00eda de tres niveles:</p>"},{"location":"modulo4/yarn_mapreduce/#a-resource-manager-el-dueno-de-la-empresa","title":"A. Resource Manager (El Due\u00f1o de la Empresa)","text":"<ul> <li>D\u00f3nde est\u00e1: En el nodo maestro.</li> <li>Misi\u00f3n: Es el autoridad m\u00e1xima de los recursos. Gestiona la RAM y CPU de todo el cl\u00faster.</li> <li>Funci\u00f3n: No sabe qu\u00e9 est\u00e1s ejecutando. [cite_start]Solo recibe peticiones (\"Necesito 4GB de RAM\") y las aprueba o deniega [cite: 306-308].</li> </ul>"},{"location":"modulo4/yarn_mapreduce/#b-node-manager-el-encargado-de-sala","title":"B. Node Manager (El Encargado de Sala)","text":"<ul> <li>D\u00f3nde est\u00e1: En cada nodo esclavo (trabajador).</li> <li>Misi\u00f3n: Vigila su propia m\u00e1quina.</li> <li>Funci\u00f3n: Informa al Resource Manager de cu\u00e1nta capacidad libre tiene y se encarga de crear los Contenedores (cajas virtuales con recursos) donde se ejecutan las tareas.</li> </ul>"},{"location":"modulo4/yarn_mapreduce/#c-application-master-el-jefe-de-proyecto-temporal","title":"C. Application Master (El Jefe de Proyecto Temporal)","text":"<ul> <li>D\u00f3nde est\u00e1: Se crea uno espec\u00edfico para cada trabajo (Job) que lanzas.</li> <li>Misi\u00f3n: Dirigir la ejecuci\u00f3n de tu programa.</li> <li>Funci\u00f3n: Negocia los recursos con el Resource Manager y luego da las \u00f3rdenes a los Node Managers. [cite_start]Cuando el trabajo termina, este jefe \"desaparece\" [cite: 320-321].</li> </ul>"},{"location":"modulo4/yarn_mapreduce/#3-configuracion-de-yarn","title":"3. Configuraci\u00f3n de YARN","text":"<p>Para activar este sistema, debemos editar dos archivos en <code>/opt/hadoop/etc/hadoop/</code>.</p> <p>1. <code>mapred-site.xml</code> Aqu\u00ed le decimos a Hadoop que deje de usar el sistema antiguo y use YARN. <pre><code>&lt;property&gt;\n    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n    &lt;value&gt;yarn&lt;/value&gt;\n&lt;/property&gt;\n</code></pre></p> <p>2. <code>yarn-site.xml</code> Aqu\u00ed configuramos qui\u00e9n es el jefe (hostname) y activamos el servicio auxiliar para que funcione el Shuffle.</p> <pre><code>&lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;\n    &lt;value&gt;NOMBRE_DE_TU_MAQUINA&lt;/value&gt; &lt;/property&gt;\n&lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n&lt;/property&gt;\n</code></pre>"},{"location":"modulo4/yarn_mapreduce/#4-mapreduce-el-flujo-de-trabajo","title":"4. MapReduce: El Flujo de Trabajo","text":"<p>MapReduce es el paradigma de programaci\u00f3n para procesar datos masivos en paralelo. Se divide en tres fases estrictas.</p>"},{"location":"modulo4/yarn_mapreduce/#fase-1-mapper-el-clasificador","title":"Fase 1: Mapper (El Clasificador)","text":"<ul> <li>Entrada: Recibe datos en bruto (l\u00edneas de texto, emails, etc.).</li> <li>Proceso: Filtra la informaci\u00f3n \u00fatil.</li> <li>Salida: Emite pares Clave-Valor.</li> <li>Importante: El Mapper NO suma ni cuenta totales. Es \"tonto\" y r\u00e1pido. [cite_start]Solo dice: \"He visto un pepe\" (<code>pepe, 1</code>) [cite: 860-862].</li> </ul>"},{"location":"modulo4/yarn_mapreduce/#fase-2-shuffle-sort-el-organizador","title":"Fase 2: Shuffle &amp; Sort (El Organizador)","text":"<ul> <li>Proceso: Es autom\u00e1tico (caja negra de Hadoop).</li> <li>[cite_start]Acci\u00f3n: Recoge todas las salidas de los miles de Mappers, las ordena alfab\u00e9ticamente y las agrupa por clave[cite: 533].</li> <li>[cite_start]Resultado: Al Reducer no le llegan datos sueltos, le llega la clave con todos sus valores juntos (Ej: <code>pepe, [1, 1, 1]</code>)[cite: 533].</li> </ul>"},{"location":"modulo4/yarn_mapreduce/#fase-3-reducer-el-contador","title":"Fase 3: Reducer (El Contador)","text":"<ul> <li>Entrada: Recibe los datos ya ordenados y agrupados.</li> <li>Proceso: Itera sobre la lista de valores y realiza la operaci\u00f3n final (sumar, calcular media, m\u00e1ximo...).</li> <li>[cite_start]Salida: El resultado final que se guarda en HDFS [cite: 589-590].</li> </ul>"}]}